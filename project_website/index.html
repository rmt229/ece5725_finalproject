
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Starter Template for Bootstrap</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- Custom styles for this template -->
    <link href="starter-template.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <!-- <script src="../../assets/js/ie-emulation-modes-warning.js"></script> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">Project name</a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="#">Home</a></li>
            <li><a href="#intro">Introduction</a></li>
            <li><a href="#obj">Project Objective</a></li>
            <li><a href="#design">Design</a></li>
            <li><a href="#drawings">Drawings</a></li>
            <li><a href="#testing">Testing</a></li>
            <li><a href="#result">Result</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">

      <div class="starter-template">
        <h1>Squid Game: Red Light, Green Light</h1>
        <p class="lead">ECE 5745 Spring 2022<br>Aditi Agarwal (aa2224) and Raquel Taborga (rmt229)</p>
      </div>

      <hr>
      <div class="center-block">
          <iframe width="640" height="360" src="https://www.youtube.com/watch?v=GuM8vTq0jd4" frameborder="0" allowfullscreen></iframe>
          <h4 style="text-align:center;">Demonstration Video</h4>
      </div>

      <hr id="intro">

      <div style="text-align:center;">
              <h2>Introduction</h2>
              <p style="text-align: left;padding: 0px 30px;">
                For this final project, we recreated the Red Light, Green Light doll from the famous Netflix series Squid Game.
                The game works by having players all start at the start line and whenever they hear the “Green Light” music, they can move forward, 
                whenever this music stops, the game is in "Red Light" mode and the players must freeze. If they are caught moving
                during the red light phase, they are out. The goal of this game is to get to the doll first and press a button on the Pi, signaling that the 
                player has crosssed the finish line. Our game has a single-player and 2-player mode.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
              The Raspberry Pi runs OpenCV to capture video stream from an attached PiCamera and TensorFlowLite (TFLite) process a frame to identify 17
              keypoints on a person to identify their pose. The Main Pi (henceforth referred to as RPiMain) controls an RGB LED strip that lights up red during the Red Phase, green during the Green phase, 
              blinks red when a player is eliminated, and oscillates rainbow once the game has a winner. When a player is eliminated, we use the keypoints
              from our pose detection to rotate a servo-mounted laser pointer at the losing player. 
              We use a second Raspberry Pi (RPi2) to play sound via Bluetooth connection to a speaker during the Green
              Light phase of the game. This is because it is impossible, due to hardware limitations in the Pi, to play sound (of any kind) while running 
              the LED library. Audio cannot play when called with a 'sudo' command, and the LED library can only run when called with a 'sudo' command. 
              </p>
      </div>

    <hr id='obj'>

      <div class="row">
          <div class="col-md-4" style="text-align:center;">
          <img class="img-rounded" src="pics/Squid_game_doll.png" alt="Doll robot setup next to doll in Squid Game" width="400" height="400">
          </div>
          <div class="col-md-8" style="font-size:18px;">
          <h2>Project Objective:</h2>
          <ul>
              <li>Use OpenCV, tflite and PiCamera to detect motion for two players</li>
              <li>Use a servo motor to point a laser pointer at whoever moves</li>  
              <li>Play the Red Light Green Light song during green stages</li>
              <li>Sync an LED strip with the proper game stage</li>
          </ul>
          </div>
      </div>

    <hr id='design'>

      <div style="text-align:center;">
              <h2>Design</h2>
              <p style="text-align: left;padding: 0px 30px;">
                This project had many moving parts; we had multiple peripheral devices and a fair amount of image processing. We will break down
                our project design into their Hardware and Software parts.
              </p>
              <h3>High Level Overview</h3>
              <p style="text-align: left;padding: 0px 30px;">
              The novel part of this project, for us, was the pose detection and image processing. We ran a 64-bit OS (Debian) on the Pi, since
              we could not find any OpenCV or TensorFlow packages whose models worked on a 32-bit kernel. The Raspberry Pi used OpenCV just to 
              interface with the PiCamera and capture frame images. We also used OpenCV to display the processed image with our keypoints. We used 
              a known model we found online (PoseNet) on TFLite to identify 17 keypoints on a person. 
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                Once we had a way to identify poses for a person frame by frame, we implemented game logic around it to only do our motion detection
                in the Red Light phase. In this game logic, we also had to play sound, run the LEDs, and trigger the standard servo motor to point 
                to the losing player. 
              </p>
              <p style="text-align: left;padding: 0px 30px;">
              For the stand, we used a premade wooden coat stand we found in the corner of the room. We encourage future students of this class
            to repurpose as much of their project as possible! We outfitted the coat stand with shelves and a hanger to mount the RPi and additional
          accessories to create a final project that looked like a life-size doll like in Squid Game.</p>
                <h3>Hardware</h3>
                <p style="text-align: left;padding: 0px 30px;">All parts mentioned are listed and linked in the References Section. </p>
                <h4>PiCamera</h4>
                <p style="text-align: left;padding: 0px 30px;">
                To capture input video stream, we used a PiCamera provided by Professor Skovira. This is made by Raspberry Pi and is very easy
                to integrate with the Pi. Within less than an hour, we were able to take pictures with the PiCamera and save onto the Pi. The PiCam 
                connects to the Pi via ribbon strip.</p>
                <h4>LED Strip</h4>
                <p style="text-align: left;padding: 0px 30px;">
                We used a 3.2ft long WS2812B LED strip. We picked this model of LED strips because this is a really easy type of LED strip to 
                configure. It has 3 pins: VCC, GND, and Control. The Control pin sends a PWM signal to the LED strip and allows you to configure
                which the specific RGB color to a specific pixel. Our strip had 60 pixels. Using the Neopixel Python library, it was straightforward 
                to control this LED strip. It requires a 5V input voltage, so we connected this to a DC voltage supply. We could have connected it to a 
                battery just as easily, this was just easy for us during debugging, and we did not need the doll to move. </p>
                <h4>Parallax Standard Servo Motor</h4>
                <p style="text-align: left;padding: 0px 30px;">
                To eliminate a player, we wanted to mount a laser onto a servo. This class gave us experience working with servo motors, and we knew from 
                past projects that we required a standard servo, not a continous servo. That is, we wanted a motor for which we could specify a particular 
                angle (PWM Duty cycle), and the motor would move to that angle and remain there. We used Professor Skovira's Parallax Standard Servo to achieve this.
                We used software-defined PWM signals using the RPi.GPIO library, but in retrospect we should have used a hardware-defined PWM pin to avoid 
                oscillatory behavior with the servo. 
                </p>
                <p style="text-align: left;padding: 0px 30px;">
                When working with lasers, it's important to take precautions so as to not blind or create eye discomfort for other people. We used 
                a weak laser pointer and angled it so that it would aim (roughly) at the neck down for our players. 
                </p>
                <h4>Speaker</h4>
                <p style="text-align: left;padding: 0px 30px;">
                To minimize our use of wires (since we had a lot), and to try something new, we opted for using a Bluetooth Speaker. This was 
                very easy to setup on the RPi. In terminal, you can call the bluetoothctl environment and connect through terminal, or simply
                connect to a new device by using the RPi UI and selecting the Bluetooth icon in the top right hand corner. To play sound, we ended up
                using pygame.mixer. We also experimented with using mplayer and PulseAudio. All of these worked, 
                we just settled on one. We downloaded our desired sound and saved it as a wav file on the SD card, then loaded this sound into the Python 
                program using pygame.mixer.
                </p>
                <p style="text-align: left;padding: 0px 30px;">
                The biggest issue with running audio was that any method of playing sound did not work when called with 'sudo'. It worked every 
                time without the 'sudo' command, with all audio player programs mentioned above. Whether we used the audio jack or Bluetooth speaker, 
                sound worked with out 'sudo', and never with 'sudo'. After much researching, changing access permissions, and 
                even enabling system-wide audio, we found a source that explained that it is impossible to run audio in 'sudo'. However, neopixel needed to be run 
                in 'sudo'. The reason for this is because they both access the same PWM pins internally, so it is impossible to grant root user permissions for audio, 
                and impossible to not allow neopixel to access those pins. On the Raspberry Pi 4, you cannot run audio and neopixel simultaneously. We offloaded 
                the responsibility of playing audio onto another RPi. Using a single GPIO pin between the two, RPi Main would pass information about being 
                in the Red State Phase (INPUT==1) or not (INPUT==0). RPi2 would only play audio on INPUT high, and pause audio on INPUT low. 
                </p>
                <h3>Software</h3>
                <p style="text-align: left;padding: 0px 30px;">
                  We developed the code so that the game can be played 
                  in 2 player mode or single player mode by making it a command-line argument.
                  Since OpenCV and tflite are heavy applications, as well as video streaming,
                  we made use of multi-threading to make our application run faster.
                </p>
                <p style="text-align: left;padding: 0px 30px;">
                  We created multiple game states: red, green, loser, winner. As shown 
                  in the project.py in the Code Appendix we have a while loop that plays the game
                  unless someone has lost or won. It chooses a random number (time_g) of seconds between 1
                  and the length of the Red Light, Green Light song to switch from being green to red,
                  and then another random number of seconds (time_r) to switch from red to green.
                </p>
                <!-- <div class="col-md-4" style="text-align:center;"> -->
                  <img class="img-rounded" src="pics/game_fsm.png" alt="FSM of the full game" width="500" height="350">
                <!-- </div> -->
                <p style="text-align: center;padding: 0px 30px;">FSM of the full game logic</p>
                <p style="text-align: left;padding: 0px 30px;">
                In the Green Light phase, we send a GPIO High output to the second RPi so that it can play
                the sound. In the Red Light phase, we initiate the Pi Camera frame fetching,
                pose detection, and motion detection. During both states if a player presses
                GPIO button 27, then they win and the game is over. To detect the button press,
                we use a callback function so that at any point in the program if a button press
                is detected the game can go to the winner state. During the winner state, the LEDs display 
                a rainbow pattern and then the program quits. The loser state happens only from 
                the red light stage if someone is detected moving. 
                </p>
                <p style="text-align: left;padding: 0px 30px;">
                For motion detection, we use multiple threads. We instatiate one thread that is an instance
                of VideoGetter, 2 threads that are instances of PoseDetect (or PoseDetect2 for 2 player), 1 thread
                that is an instance of VideoShower, and 1 thread that is an instance of MotionDetect. All 
                of the threads are running constantly but only take action once their input is not empty.
                </p>
                <!-- <div class="col-md-4" style="text-align:center;"> -->
                  <img class="img-rounded" src="pics/thread_flow.png" alt="Threads" width="400" height="400">
                <p style="text-align: center;padding: 0px 30px;">Threads for one-player mode</p>
                <!-- </div> -->
                <p style="text-align: left;padding: 0px 30px;">
                  The VideoGetter thread captures frames from the PiCamera using OpenCV. The frames from VideoGetter
                  feeds into the PoseDetect threads. PoseDetect takes in a frame and runs pose detetection using a
                  tflite PoseDetection model. The tflite model takes in the image and outputs the keypoint coordinates
                  which are coordinates of different body parts (eyes, nose, shoulders, etc.). For 2 player-mode,
                  the input frame is cut in half and PoseDetect2 detects for each side of the frame and places the images
                  with the coordinates drawn on them next to each other.The PoseDetect code then uses those 
                  coordinates to draw on the figure where the detection is and also outputs the coordinates
                  in a list. The image showing the coordinate drawing is then sent to video show-er which displays the
                  frame on the monitor. MotionDetect takes in 2 lists of coordinates and determines if the keypoints
                  are different enough between frames. If they are, then it changes its did_move parameter to true and
                  the main program sends a PWM output signal to the servo using the servo PWM value calculated from motion
                  detector. For 2 player mode, there are 2 motion detecters which take in each players keypoints to detect
                  motion.
                </p>
                
      </div>

    <hr id='drawings'>

      <div style="text-align:center;">
              <h2>Drawings</h2>
              <p style="text-align: left;padding: 0px 30px;">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum lorem nulla, consectetur at leo vel, pretium bibendum nisl. Cras blandit quam a enim ultrices, eu convallis enim posuere. Donec eleifend enim sed purus consectetur, vitae cursus lectus varius. Vivamus consectetur felis nec est venenatis posuere. Phasellus vitae aliquet erat. In laoreet lacinia mollis. Quisque iaculis nisl fermentum pharetra lobortis. Donec rhoncus dui sem, ac molestie leo tristique vel. Phasellus in nibh feugiat, fringilla lectus in, elementum magna. Etiam quis dui condimentum, tempus ex in, dapibus est. Cras ut congue augue. Donec ac enim ex. Ut id tristique risus, vel porttitor quam. Sed ultricies enim eu nibh porttitor, vel sodales enim feugiat. Fusce volutpat venenatis magna ac ultrices. Curabitur eget urna ut nulla mattis convallis non eu diam.</p>
      </div>

    <hr id='testing'>

      <div style="text-align:center;">
              <h2>Testing</h2>
              <p style="text-align: left;padding: 0px 30px;">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum lorem nulla, consectetur at leo vel, pretium bibendum nisl. Cras blandit quam a enim ultrices, eu convallis enim posuere. Donec eleifend enim sed purus consectetur, vitae cursus lectus varius. Vivamus consectetur felis nec est venenatis posuere. Phasellus vitae aliquet erat. In laoreet lacinia mollis. Quisque iaculis nisl fermentum pharetra lobortis. Donec rhoncus dui sem, ac molestie leo tristique vel. Phasellus in nibh feugiat, fringilla lectus in, elementum magna. Etiam quis dui condimentum, tempus ex in, dapibus est. Cras ut congue augue. Donec ac enim ex. Ut id tristique risus, vel porttitor quam. Sed ultricies enim eu nibh porttitor, vel sodales enim feugiat. Fusce volutpat venenatis magna ac ultrices. Curabitur eget urna ut nulla mattis convallis non eu diam.</p>
      </div>

    <hr id='result'>

      <div style="text-align:center;">
              <h2>Result</h2>
              <p style="text-align: left;padding: 0px 30px;">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum lorem nulla, consectetur at leo vel, pretium bibendum nisl. Cras blandit quam a enim ultrices, eu convallis enim posuere. Donec eleifend enim sed purus consectetur, vitae cursus lectus varius. Vivamus consectetur felis nec est venenatis posuere. Phasellus vitae aliquet erat. In laoreet lacinia mollis. Quisque iaculis nisl fermentum pharetra lobortis. Donec rhoncus dui sem, ac molestie leo tristique vel. Phasellus in nibh feugiat, fringilla lectus in, elementum magna. Etiam quis dui condimentum, tempus ex in, dapibus est. Cras ut congue augue. Donec ac enim ex. Ut id tristique risus, vel porttitor quam. Sed ultricies enim eu nibh porttitor, vel sodales enim feugiat. Fusce volutpat venenatis magna ac ultrices. Curabitur eget urna ut nulla mattis convallis non eu diam.</p>
      </div>

    <hr>

    <div class="row" style="text-align:center;">
          <h2>Work Distribution</h2>
          <div style="text-align:center;">
              <img class="img-rounded" src="pics/group.jpg" alt="Generic placeholder image" style="width:80%;">
              <h4>Project group picture</h4>
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/a.png" alt="Generic placeholder image" width="240" height="240">
              <h3>Rick</h3>
              <p class="lead">netid@cornell.edu</p>
              <p>Designed the overall software architecture (Just being himself).
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/b.png" alt="Generic placeholder image" width="240" height="240">
              <h3>Morty</h3>
              <p class="lead">netid@cornell.edu</p>
              <p>Tested the overall system.
          </div>
      </div>

    <hr>
      <div style="font-size:18px">
          <h2>Parts List</h2>
          <ul>
              <li>Raspberry Pi - Provided in lab</li>
              <li>Raspberry Pi Camera V2 - Provided in lab/li>
              <a href="https://www.amazon.com/dp/B01MG49QKD?ref=ppx_pop_mob_ap_share&th=1"><li>Alitove 60 Pixels LED Strip- $9.99</li></a>
              <a href="https://www.amazon.com/dp/B09PRFDG1L?ref=ppx_pop_mob_ap_share"><li>Cat Laser Pointer- $7.99</li></a>
              <li>LEDs, Resistors, Servo and Wires - Provided in lab</li>
          </ul>
          <h3>Total: $17.98</h3>
      </div>
      <hr>
      <div style="font-size:18px">
          <h2>References</h2>
          <a href="https://picamera.readthedocs.io/">PiCamera Document</a><br>
          <a href="https://www.parallax.com/product/parallax-standard-servo/f">Parallax Standard Servo Datasheet</a><br>
          <a href="https://learn.adafruit.com/neopixels-on-raspberry-pi">Adafruit NeoPixel Library</a><br>
          <a href="https://medium.com/analytics-vidhya/pose-estimation-on-the-raspberry-pi-4-83a02164eb8e">Pose Estimation Blog + Code</a><br>
          <a href="https://www.tensorflow.org/lite/examples/pose_estimation/overview">TFLite Pose Estimation Model</a><br>
          <a href="http://getbootstrap.com/">Bootstrap for this website</a><br>
          <a href="https://sourceforge.net/p/raspberry-gpio-python/wiki/Home/">R-Pi GPIO Document</a><br>
          
      </div>

    <hr>

      <div class="row">
              <h2>Code Appendix</h2>
              <pre><code>
// Hello World.c
int main(){
  printf("Hello World.\n");
}
              </code></pre>
      </div>

    </div><!-- /.container -->




    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script> -->
  </body>
</html>
